{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) Progress made thus far\n",
        "\n",
        "  - Initial setup\n",
        "  - Loading the data\n",
        "  - Starting to learn libraries\n",
        "  - determined kaggle data source\n",
        "\n",
        "2) Remaining tasks\n",
        "\n",
        "  - Fix startup issues\n",
        "  - Text preprocessing/wrangling data using NLTK\n",
        "  - Feature extraction\n",
        "  - Train-Test Split\n",
        "  - Brainstorm/design sentiment analyzer model (initially Naive Bayes Classifier)\n",
        "  - Implement Naive Bayes Classifier\n",
        "  - Test Naive Bayes Classifier for performance on a set of testing data\n",
        "  - If this doesn't prove effective based on our evaluation, we will convert text data into TF-IDF vectors and then apply Support Vector Machines\n",
        "  - Compare SVM to Naive Bayes Classifier on the same set of testing data\n",
        "\n",
        "\n",
        "3)Any challenges/issues being faced\n",
        "\n",
        "  - Learning the libraries (nltk, pytorch, scikit-learn)\n",
        "  - Importation issues (should be fixed relatively quickly)\n",
        "  - More will likely arise as we finish remaining tasks but we will tackle/overcome each\n",
        "  "
      ],
      "metadata": {
        "id": "a5oiWHBO3W-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "bxgC4aKn3RJj",
        "outputId": "e612e691-780d-4b70-8a3d-4184650fbdca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ef1f3d46d7bd>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    tokens = nltk.word_tokenize() for polarity in train_df['polarity']\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# https://www.kaggle.com/code/kritanjalijain/amazon-reviews-starter-nlp/notebook\n",
        "\n",
        "\"\"\"\n",
        "polarity - 1 for negative and 2 for positive\n",
        "title - review heading\n",
        "text - review body\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tarfile # this is to extract the data from that .tgz file\n",
        "\n",
        "# get all of the data out of that .tgz\n",
        "amazon_reviews = tarfile.open('/kaggle/input/amazon-reviews/amazon_review_polarity_csv.tgz')\n",
        "amazon_reviews.extractall('data')\n",
        "amazon_reviews.close()\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('./'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# check out what the data looks like before you get started\n",
        "# look at the training data set\n",
        "train_df = pd.read_csv('./data/amazon_review_polarity_csv/train.csv', header=None)\n",
        "print(train_df.head())\n",
        "\n",
        "# look at the test data set\n",
        "test_df = pd.read_csv('./data/amazon_review_polarity_csv/test.csv', header=None)\n",
        "print(test_df.head())\n",
        "\n",
        "import nltk\n",
        "tokens = [nltk.word_tokenize(polarity) for polarity in train_df['polarity']]"
      ]
    }
  ]
}